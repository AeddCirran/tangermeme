{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "987a2112-fe3f-4a13-a7cf-1c2817e77dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407999a8-ae5a-461a-9c34-fa86f5799da9",
   "metadata": {},
   "source": [
    "### Tutorial 11: Cartesian Product\n",
    "\n",
    "Sometimes, when using multi-input models, one wants to run a function on the cartesian product between the two inputs. Put another way, given a sequence input $X$ and some other input $Y$, one wants to make predictions for $X_0 Y_0, X_0 Y_1... X_n Y_m$ where $X$ has $n$ elements and $Y$ has $m$ inputs. Of course, one could simply run each of the functions for a fixed value of $Y$ across all $X$ (or vice-versa) and then change the value of $Y$ each time. But that's not convenient, and can have challenges with efficiency if one axis is held constant each time but the other axis is small, i.e., if your batching setup is that you run all sequences through the model for each example in $Y$ but you only have a very small number of sequences you're considering.\n",
    "\n",
    "Instead, `tangermeme` provides a general-purpose `apply_product` function that takes in a function, model, and data, and handles running the function on the cartesian product of the inputs in a batch- and memory-efficient manner. In theory, the most conceptually simple way to set up this function is to unravel the entire product into CPU memory and then run the provided function on the entire thing. However, this can take a huge amount of memory, particularly if the product is over several elements. In practice, it's better to construct each batch iteratively and only run one batch at a time through the model. That way, only the model predictions are stored in CPU memory as opposed to the (usually much larger) inputs.\n",
    "\n",
    "#### Apply Product\n",
    "\n",
    "More concretely, to use the `apply_product` function, one provides a function, e.g., `predict`, `marginalize`, etc..., a model, the sequence input `X`, and any number of additional arguments in `args`. The first dimension of these arguments do not have to match. Unlike the core functions like `predict`, the function is not just being applied to `X` and the series of arguments. Rather, the point of `apply_product` is to apply the function to the product of arguments and get a tensor back where the first dimensions are `len(X), len(args[0]), len(args[1])...` and then the dimensions of the predictions from the model.\n",
    "\n",
    "Let's see this in action with a toy model that takes an input, flattens it, and applies an optional linear transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95483942-bb23-42f4-be15-d461e1c1bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class FlattenDense(torch.nn.Module):\n",
    "\tdef __init__(self, length=10):\n",
    "\t\tsuper(FlattenDense, self).__init__()\n",
    "\t\tself.dense = torch.nn.Linear(length*4, 3)\n",
    "\n",
    "\tdef forward(self, X, alpha=0, beta=1):\n",
    "\t\tX = X.reshape(X.shape[0], -1)\n",
    "\t\treturn self.dense(X) * beta + alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5f8445-bc2a-4280-a975-c9edde925e79",
   "metadata": {},
   "source": [
    "This model has two optional inputs: `alpha`, which is an additive constant on the output from the dense layer, and `beta`, which is a multiplicative factor. Yes, it's redundant to have these factors after a dense layer which is doing a pretty similar thing, but this is meant just to demonstrate how to use the functions and to confirm that it's doing the expected thing.\n",
    "\n",
    "##### Predict\n",
    "\n",
    "Let's start off by generating some random one-hot encodings and running the model on them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ba99f7-ed62-4585-a68a-c45fd7b4869a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3154, -0.1625, -0.3183],\n",
       "        [-0.0866,  0.5461, -0.0244],\n",
       "        [ 0.3089, -0.2828, -0.1485],\n",
       "        [ 0.1671, -0.1341, -0.3094],\n",
       "        [-0.0627,  0.0088,  0.3471]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tangermeme.utils import random_one_hot\n",
    "torch.manual_seed(0)\n",
    "\n",
    "X = random_one_hot((5, 4, 10), random_state=0).float()\n",
    "model = FlattenDense()\n",
    "\n",
    "y = model(X)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0035f43-8f65-4796-8e0c-3f52d65f8e09",
   "metadata": {},
   "source": [
    "We can confirm that the `apply_product` is working correctly by passing in `alpha` and `beta` values that are equal to their defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6517acfe-9362-4539-be75-53d9de279e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3154, -0.1625, -0.3183],\n",
       "        [-0.0866,  0.5461, -0.0244],\n",
       "        [ 0.3089, -0.2828, -0.1485],\n",
       "        [ 0.1671, -0.1341, -0.3094],\n",
       "        [-0.0627,  0.0088,  0.3471]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tangermeme.predict import predict\n",
    "from tangermeme.product import apply_product\n",
    "\n",
    "torch.manual_seed(0)\n",
    "alpha = torch.zeros(1, 1)\n",
    "beta = torch.ones(1, 1)\n",
    "\n",
    "y_product = apply_product(predict, model, X, args=(alpha, beta))[:, 0, 0]\n",
    "y_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610f7b51-d38a-42a6-b47c-b2a597f87feb",
   "metadata": {},
   "source": [
    "Looks like the values are identical. We have to index the first element of the second and third dimensions because dimensions of size 1 are added. \n",
    "\n",
    "As mentioned repeatedly, `tangermeme` tries to be as assumption-free as possible. This means that `alpha` and `beta` can be any shape that works with the math provided in the implementation. Because three outputs are generated for each example, we can have our `alpha` and `beta` tensors also have three dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16a25e23-898d-4989-b972-b9c3000bb5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 1, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = torch.zeros(1, 3)\n",
    "beta = torch.ones(1, 3)\n",
    "\n",
    "y_product = apply_product(predict, model, X, args=(alpha, beta))\n",
    "y_product.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3e7425-aedb-462b-a1cb-30af1df34cf8",
   "metadata": {},
   "source": [
    "If we wanted to scan over a range of `alpha` and `beta` values, we just need to pass in a bigger tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b65bb80-2171-4125-a974-58d51d695264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 54, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = torch.zeros(10, 3)\n",
    "beta = torch.ones(54, 3)\n",
    "\n",
    "y_product = apply_product(predict, model, X, args=(alpha, beta))\n",
    "y_product.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a12bbe-cccf-4b95-8e80-5c8a67677247",
   "metadata": {},
   "source": [
    "Now, we can check that the values are correct even when adding the additional arguments. Let's start off by considering only the `alpha` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac74e8a9-6972-4720-82f0-ab733a986d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2256,  1.3785,  1.2227],\n",
       "         [-0.6089, -0.4559, -0.6117],\n",
       "         [-2.4942, -2.3412, -2.4970]],\n",
       "\n",
       "        [[ 1.4544,  2.0871,  1.5166],\n",
       "         [-0.3800,  0.2527, -0.3178],\n",
       "         [-2.2654, -1.6327, -2.2032]],\n",
       "\n",
       "        [[ 1.8499,  1.2582,  1.3925],\n",
       "         [ 0.0155, -0.5762, -0.4419],\n",
       "         [-1.8699, -2.4616, -2.3273]],\n",
       "\n",
       "        [[ 1.7081,  1.4069,  1.2316],\n",
       "         [-0.1263, -0.4275, -0.6028],\n",
       "         [-2.0117, -2.3129, -2.4882]],\n",
       "\n",
       "        [[ 1.4783,  1.5498,  1.8881],\n",
       "         [-0.3561, -0.2846,  0.0537],\n",
       "         [-2.2414, -2.1700, -1.8317]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "alpha = torch.randn(3, 1)\n",
    "\n",
    "y_product = apply_product(predict, model, X, args=(alpha,))\n",
    "y_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54c1f60-581e-4b45-a00b-1c6748219439",
   "metadata": {},
   "source": [
    "Since all we are doing is adding a value in a broadcasted manner, we can easily check by adding in the appropriate dimensions and doing the addition outside the context of this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62f80cc6-524d-4b8f-8108-244889f56432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2256,  1.3785,  1.2227],\n",
       "         [-0.6089, -0.4559, -0.6117],\n",
       "         [-2.4942, -2.3412, -2.4970]],\n",
       "\n",
       "        [[ 1.4544,  2.0871,  1.5166],\n",
       "         [-0.3800,  0.2527, -0.3178],\n",
       "         [-2.2654, -1.6327, -2.2032]],\n",
       "\n",
       "        [[ 1.8499,  1.2582,  1.3925],\n",
       "         [ 0.0155, -0.5762, -0.4419],\n",
       "         [-1.8699, -2.4616, -2.3273]],\n",
       "\n",
       "        [[ 1.7081,  1.4069,  1.2316],\n",
       "         [-0.1263, -0.4275, -0.6028],\n",
       "         [-2.0117, -2.3129, -2.4882]],\n",
       "\n",
       "        [[ 1.4783,  1.5498,  1.8881],\n",
       "         [-0.3561, -0.2846,  0.0537],\n",
       "         [-2.2414, -2.1700, -1.8317]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unsqueeze(1) + alpha.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5b87e1-6e62-4402-b7b0-0eaa9a346ada",
   "metadata": {},
   "source": [
    "Same values. If we add in a `beta` value, we see the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95994671-bc0a-46a3-9a4a-6f317025d147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3617,  1.4486,  1.3601],\n",
       "         [-0.4727, -0.3858, -0.4743],\n",
       "         [-2.3581, -2.2711, -2.3597]],\n",
       "\n",
       "        [[ 1.4918,  1.8514,  1.5271],\n",
       "         [-0.3427,  0.0170, -0.3073],\n",
       "         [-2.2280, -1.8684, -2.1926]],\n",
       "\n",
       "        [[ 1.7166,  1.3803,  1.4566],\n",
       "         [-0.1178, -0.4542, -0.3779],\n",
       "         [-2.0032, -2.3395, -2.2632]],\n",
       "\n",
       "        [[ 1.6360,  1.4648,  1.3651],\n",
       "         [-0.1984, -0.3696, -0.4693],\n",
       "         [-2.0838, -2.2550, -2.3546]],\n",
       "\n",
       "        [[ 1.5054,  1.5460,  1.7383],\n",
       "         [-0.3290, -0.2884, -0.0961],\n",
       "         [-2.2144, -2.1738, -1.9815]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "alpha = torch.randn(3, 1)\n",
    "beta = torch.randn(1, 1)\n",
    "\n",
    "y_product = apply_product(predict, model, X, args=(alpha, beta))[:, :, 0]\n",
    "y_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34be1d26-bfb8-4146-a8ad-1fdac5a78521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3617,  1.4486,  1.3601],\n",
       "         [-0.4727, -0.3858, -0.4743],\n",
       "         [-2.3581, -2.2711, -2.3597]],\n",
       "\n",
       "        [[ 1.4918,  1.8514,  1.5271],\n",
       "         [-0.3427,  0.0170, -0.3073],\n",
       "         [-2.2280, -1.8684, -2.1926]],\n",
       "\n",
       "        [[ 1.7166,  1.3803,  1.4566],\n",
       "         [-0.1178, -0.4542, -0.3779],\n",
       "         [-2.0032, -2.3395, -2.2632]],\n",
       "\n",
       "        [[ 1.6360,  1.4648,  1.3651],\n",
       "         [-0.1984, -0.3696, -0.4693],\n",
       "         [-2.0838, -2.2550, -2.3546]],\n",
       "\n",
       "        [[ 1.5054,  1.5460,  1.7383],\n",
       "         [-0.3290, -0.2884, -0.0961],\n",
       "         [-2.2144, -2.1738, -1.9815]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unsqueeze(1) * beta.unsqueeze(0) + alpha.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeca905-3a96-4763-99b2-dda39f10cdad",
   "metadata": {},
   "source": [
    "##### Marginalize\n",
    "\n",
    "Naturally, `apply_product` is not restricted to working with the `predict` function. We can also use the `marginalize` function if we want to run the marginalization experiments on a range of additional arguments. If we want to pass additional arguments into the function (as opposed to the model) we can list them after `X`. In this case, we can just write the motif we want to marginalize over as a string, just like we would if we used the marginalize function itself. Importantly, arguments into the <i>model</i> have to be specified using the `args` keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e86c651-38b9-497d-8d10-e7069e3d65bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3, 1, 3]), torch.Size([5, 3, 1, 3]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tangermeme.marginalize import marginalize\n",
    "\n",
    "y_before, y_after = apply_product(marginalize, model, X, \"TGA\", args=(alpha, beta))\n",
    "y_before.shape, y_after.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4928b5-2239-4994-97c8-4dde216d4be6",
   "metadata": {},
   "source": [
    "Since `alpha` is an addition, we shouldn't see any effect on the difference between `y_after` and `y_before` across those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d24dd7e-8490-480e-9760-1db8067d855a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1444, -0.0518,  0.0818],\n",
       "         [ 0.1444, -0.0518,  0.0818],\n",
       "         [ 0.1444, -0.0518,  0.0818]],\n",
       "\n",
       "        [[-0.0629,  0.0639,  0.1607],\n",
       "         [-0.0629,  0.0639,  0.1607],\n",
       "         [-0.0629,  0.0639,  0.1607]],\n",
       "\n",
       "        [[-0.0593,  0.2247,  0.0418],\n",
       "         [-0.0593,  0.2247,  0.0418],\n",
       "         [-0.0593,  0.2247,  0.0418]],\n",
       "\n",
       "        [[-0.0770,  0.0949,  0.1096],\n",
       "         [-0.0770,  0.0949,  0.1096],\n",
       "         [-0.0770,  0.0949,  0.1096]],\n",
       "\n",
       "        [[ 0.0569,  0.0804,  0.0643],\n",
       "         [ 0.0569,  0.0804,  0.0643],\n",
       "         [ 0.0569,  0.0804,  0.0643]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_after - y_before)[:, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e97ee8-d417-41e6-ac92-e6763116266d",
   "metadata": {},
   "source": [
    "However, if we pass in a bunch of different values for `beta`, we can see that the difference between `y_after` and `y_before` changes with the changing `beta` values. This is what you'd expect because `beta` is multiplicative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "662e1b95-cf32-45a5-9e79-cc9dde833691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0745,  0.0268, -0.0422],\n",
       "         [-0.5534,  0.1987, -0.3134],\n",
       "         [ 0.1444, -0.0518,  0.0818]],\n",
       "\n",
       "        [[ 0.0325, -0.0330, -0.0830],\n",
       "         [ 0.2411, -0.2448, -0.6161],\n",
       "         [-0.0629,  0.0639,  0.1607]],\n",
       "\n",
       "        [[ 0.0306, -0.1160, -0.0216],\n",
       "         [ 0.2273, -0.8612, -0.1602],\n",
       "         [-0.0593,  0.2247,  0.0418]],\n",
       "\n",
       "        [[ 0.0397, -0.0490, -0.0566],\n",
       "         [ 0.2951, -0.3636, -0.4200],\n",
       "         [-0.0770,  0.0949,  0.1096]],\n",
       "\n",
       "        [[-0.0294, -0.0415, -0.0332],\n",
       "         [-0.2180, -0.3082, -0.2463],\n",
       "         [ 0.0569,  0.0804,  0.0643]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "alpha = torch.randn(1, 1)\n",
    "beta = torch.randn(3, 1)\n",
    "\n",
    "y_before, y_after = apply_product(marginalize, model, X, \"TGA\", args=(alpha, beta))\n",
    "(y_after - y_before)[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5585c0e-8a60-49a4-b897-59152a28f429",
   "metadata": {},
   "source": [
    "##### Other Functions\n",
    "\n",
    "Any other function in `tangermeme` that takes in `args` can be wrapped using `apply_product`. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
