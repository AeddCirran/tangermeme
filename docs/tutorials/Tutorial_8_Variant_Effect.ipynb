{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20e70aed-28af-41b4-87ad-389816ef8397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c9df03-3840-4c82-b964-5ab94d23cd86",
   "metadata": {},
   "source": [
    "### Tutorial 8: Variant Effect\n",
    "\n",
    "A common use-case of sequence-based machine learning methods is predicting the effects of variants. By comparing the predictions of the model before and after incorporating the variant one can evaluate the predicted effect and, potentially, better understand the mechanism of its action. For example, if a variant was predicted to stop the binding of some particular protein in an enhancer, one could determine that (1) the variant could be involved in some change in phenotype and that (2) the reason it is involved is by blocking the binding of this protein which is important in some downstream pathway. In contrast, if a variant does not change the predictions from the model, potentially it is not involved with the change in phenotype.\n",
    "\n",
    "A challenge with evaluating the effects of variants is that there are many kinds of variants and some kinds are not trivial to calculate the effect for. The most basic kind are <i>substitutions</i>, where one character is changed into another. A more complicated pair of variant types are called <i>indels</i> (or insertions/deletions), where one character is inserted into or deleted from a sequence. And, finally, there are <i>structural variants</i>, where large blocks of sequence are inserted, deleted, or flipped, with respect to a reference sequence.\n",
    "\n",
    "Orthogonally to the type of mutation being considered, the evaluation can be done in two settings: <i>marginal</i>, where each variant of considered individually and independently from other variants, or <i>joint</i>, where all variants are incorporated simultaneously and the effect of each variant is just the difference in model predictions when centered on that variant.\n",
    "\n",
    "Here, we will explore how to calculate the effect of substitutions and indels in the marginal setting. Note that the following examples are genomics based but the library and functions are general to any type of bio-sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4d32fa-2035-413e-9c36-0f14206f3026",
   "metadata": {},
   "source": [
    "#### Substitutions\n",
    "\n",
    "The simplest form of variant is the substitution, where one character is exchanged for another. These variants are the simplest to evaluate because one can simply extract reference sequences centered at the mutations and then swap out the characters.\n",
    "\n",
    "We can use `tangermeme` to calculate the effect of each substitution individually using the `marginal_substitution_effect` function. This function takes in a model, the filename of a FASTA file or a dictionary where the keys are the names like in a FASTA file and the values are one-hot encoded sequences, and the variants as a pandas DataFrame. The variants must have the first column be the key (like in the FASTA file or dictionary keys), the second column by the position (ZERO INDEXED, NOT ONE INDEXED LIKE VCFS), and the third column is the new character. Note that this differs slightly from VCF format in that you do not need to include the identity of the original character, since that information would not be used by the function. The names of the columns do not matter, only their order.\n",
    "\n",
    "For the purpose of demontrating the usage we can use our simple untrained dense model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8759abb6-f4a4-42d7-962b-4a86b0a1907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tangermeme.utils import random_one_hot\n",
    "\n",
    "class FlattenDense(torch.nn.Module):\n",
    "\tdef __init__(self, seq_len=10):\n",
    "\t\tsuper(FlattenDense, self).__init__()\n",
    "\t\tself.dense = torch.nn.Linear(seq_len*4, 3)\n",
    "\t\tself.seq_len = seq_len\n",
    "\n",
    "\tdef forward(self, X, alpha=0, beta=1):\n",
    "\t\tX = X.reshape(X.shape[0], self.seq_len*4)\n",
    "\t\treturn self.dense(X) * beta + alpha\n",
    "\n",
    "model = FlattenDense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb0c19c-02db-40d0-89b7-b96747480dd9",
   "metadata": {},
   "source": [
    "Instead of pointing to a FASTA file on disk, we can pass in a dictionary to make it clearer to us what's happening in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5083f7ba-2203-4aad-b5fb-4ec0bff3189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tangermeme.utils import one_hot_encode\n",
    "\n",
    "X = {'chr1': one_hot_encode(\"ACCAGTAGTGTACCCACGTTGACCTA\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cc5a32-5e9b-4ab0-8a24-9d05440a8875",
   "metadata": {},
   "source": [
    "Next, let's create the DataFrame. This has the first few columns of a VCF file but does not have the ones related to quality or other metadata as decisions on how to use those to filter variants should be done by the user independently. Here, we can specify two substitutions from the given sequence. Remember that we also do not need to provide the original character at each position like a VCF file does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9465464-56a2-4ea0-87b0-c3141b67561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "variants = pandas.DataFrame({\n",
    "    'chrom': ['chr1', 'chr1'],\n",
    "    'pos': [8, 14],\n",
    "    'alt': ['A', 'G']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a1173d-6899-4c8e-918d-81660af6c789",
   "metadata": {},
   "source": [
    "Now, we can use the function to calculate variant effect. This function will return the predictions on the original sequence when centered at the position that the substitution will occur, and the predictions after incorporating the mutation. When using the functions starting with `marginal`, each variant is considered independently of the others. Specifically, each example will contain only one mutation in it even if multiple provided mutations fall within the same window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90bb12a1-659d-4706-8315-82ecc970dc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/jmschr/github/tangermeme/tangermeme/ersatz.py:358: NumbaDeprecationWarning: \u001b[1mThe keyword argument 'nopython=False' was supplied. From Numba 0.59.0 the default is being changed to True and use of 'nopython=False' will raise a warning as the argument will have no effect. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit(params, nopython=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tangermeme.variant_effect import marginal_substitution_effect\n",
    "\n",
    "y_orig, y_var = marginal_substitution_effect(model, X, variants, in_window=10, device='cpu')\n",
    "y_orig.shape, y_var.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f791f2e-9896-4e96-9bdc-76bfd838ff2d",
   "metadata": {},
   "source": [
    "The tensors have the shape `(2, 3)` because there are two variants to evaluate the effect of, and the model returns three predictions per example.\n",
    "\n",
    "Importantly, `tangermeme` does not force the user to adopt a specific distance function. Rather, the functions returns the raw predictions with and without the substitutions and allows the user to define their own distance. For example, we could use a simple Euclidean distance function to calculate the difference between predictions before and after including the substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46965ff7-0a87-4681-a318-0454c68e6c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3576, 0.1783])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(torch.sum((y_var - y_orig) ** 2, dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bbbc6b-f867-4f1d-87a7-10be8c850f45",
   "metadata": {},
   "source": [
    "More generally, these functions are meant to be the base operation that your downstream functions are built off of. In your library, you might write your own `variant_effect` function with a similar signature, call this function to get the predictions, calculate distance in the manner you choose, and return that -- either individually, or as part of the variant DataFrame that was passed in originally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdab2c5d-73a4-4fba-909c-e239699c0fee",
   "metadata": {},
   "source": [
    "#### Deletions\n",
    "\n",
    "Another form of mutation is a deletion, where a character is removed from the sequence. Evaluating deletions is a little more challenging than substitutions because, with substitutions, every character remains the same except for the substitution and the length of the sequence does not change. With a deletion, many characters will change because they are being moved over by one position. Further, the sequence after the deletion will be one position shorter than the original sequence. This function overcome this issue by initially loading up a window with one additional position on the right hand side for the sequence to use after the deletion and excluding that position for the original sequence. So, if the original sequence were `[ACGT]A` with the A on the right side being excluded because the window size were four and we wanted to delete the C, the two examples fed into the model would be `ACGT` and `AGTA`.\n",
    "\n",
    "The API for deletions is very similar to that of substitutions. However, the dataframe is even easier because you only need to pass in keys and positions without needing original or alternate characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30d3c1da-32e1-4af8-bab8-5363c9b603d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = pandas.DataFrame({\n",
    "    'chrom': ['chr1', 'chr1'],\n",
    "    'pos': [8, 14]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee67cc33-f950-4471-8fc9-0a7bd1ed8187",
   "metadata": {},
   "source": [
    "The function signature is identical as for substitutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84896e69-2696-4368-8a00-ed1ed7db805d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tangermeme.variant_effect import marginal_deletion_effect\n",
    "\n",
    "y_orig, y_var = marginal_deletion_effect(model, X, variants, in_window=10, device='cpu')\n",
    "y_orig.shape, y_var.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f7d0f9-839a-48ad-a405-90f7062e736f",
   "metadata": {},
   "source": [
    "Like with substitutions, you get the predictions before and after the incorporation of the variant and can so then define your own distance measure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfa13f3-cc22-4218-92cf-ad8a9aa11821",
   "metadata": {},
   "source": [
    "#### Insertions\n",
    "\n",
    "The conceptual opposite of a deletion is an insertion, where one character is inserted into a sequence. Rather than loading up an additional character, the original sequence remains the same as before but the ersatz sequence contains an inserted character in the middle and trims one character off the right hand side. \n",
    "\n",
    "Similarly to substititons, you need to define the keys, positions, and the character to be inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c8b4b6c-d373-46c9-b8a5-0034db596a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = pandas.DataFrame({\n",
    "    'chrom': ['chr1', 'chr1'],\n",
    "    'pos': [8, 14],\n",
    "    'alt': ['A', 'G']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc627c53-3122-4266-aa11-2b1227e74f01",
   "metadata": {},
   "source": [
    "Likewise, the function signature is the same as the other two functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "201baa42-daeb-49b4-945c-f1386f79efc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tangermeme.variant_effect import marginal_insertion_effect\n",
    "\n",
    "y_orig, y_var = marginal_insertion_effect(model, X, variants, in_window=10, device='cpu')\n",
    "y_orig.shape, y_var.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce94596-6b80-47e0-85dc-bca364dcad09",
   "metadata": {},
   "source": [
    "#### How can I implement my own?\n",
    "\n",
    "Maybe you disagree with some of the choices made in calculating the variant effect score. If you'd like to change any of the details you can just copy/paste the functions and make the changes you'd like or write something from scratch. Ultimately, the function should take a form like below, where the edits are made using whatever strategy the user would like and then the `predict` function is called on the original sequences and the edited sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "242224c8-6d10-4d3e-a590-02715466f5d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1181983125.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    def my_variant_effect_method(model, X, variants, ...):\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def my_variant_effect_method(model, X, variants, ...):\n",
    "    X_alt = ... # Incorporate the changes you'd like\n",
    "\n",
    "    return predict(model, X, ...), predict(model, X_alt, ...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
