{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "987a2112-fe3f-4a13-a7cf-1c2817e77dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407999a8-ae5a-461a-9c34-fa86f5799da9",
   "metadata": {},
   "source": [
    "### Tutorial B7: Cartesian Product\n",
    "\n",
    "Sometimes, when using multi-input models, one wants to run a function on the cartesian product between the two inputs. Put another way, given a sequence input $X$ and some other input $Y$, one wants to make predictions for $(X_0, Y_0), (X_0, Y_1)... (X_n, Y_m)$ where $X$ has $n$ elements and $Y$ has $m$ inputs. Of course, one could simply run each of the functions for a fixed value of $Y$ across all $X$ (or vice-versa) and then change the value of $Y$ each time. However, having to code this yourself is not convenient and can easily be implemented in an inefficient manner, particularly if one is going to encounter settings where they sometimes have a small number of $X$ and other times have a small number of $Y$. \n",
    "\n",
    "Instead of having to implement this yourself, `tangermeme` provides `apply_pairwise` and `apply_product` to make applying functions across products like this easy and memory efficient. `apply_pairwise` yields examples from the pairwise product between `X` and a set of arguments whose ordering is paired. For example, if you have $X$ that has $5$ elements in it and arguments $a$ and $b$ that each have $3$, you would get $(X_0, a_0, b_0), (X_0, a_1, b_1), ... (X_4, a_1, b_1), (X_4, a_2, b_2)$ In contrast, `apply_product` applies a function to the cartesian product of the sequences and each of the arguments provided. This means that you would instead get $(X_0, a_0, b_0), (X_0, a_0, b_1), (X_0, a_0, b_2) ... (X_2, a_0, b_1)... (X_4, a_2, b_1), (X_4, a_2, b_2)$. Although `apply_product` is more general, in the sense that it can be applied across any number of arguments, it is not the right function to run when you have paired inputs like cell information. \n",
    "\n",
    "In theory, the most conceptually simple way to set up this function is to unravel the entire product into CPU memory and then run the provided function on the entire thing. However, this can take a huge amount of memory, particularly if the product is over several elements. In practice, it's better to construct each batch iteratively and only run one batch at a time through the model. That way, only the model predictions are stored in CPU memory as opposed to the (usually much larger) inputs.\n",
    "\n",
    "Let's see all this in action with a toy model that takes an input, flattens it, and applies an optional linear transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95483942-bb23-42f4-be15-d461e1c1bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class FlattenDense(torch.nn.Module):\n",
    "\tdef __init__(self, length=10):\n",
    "\t\tsuper(FlattenDense, self).__init__()\n",
    "\t\tself.dense = torch.nn.Linear(length*4, 3)\n",
    "\n",
    "\tdef forward(self, X, alpha=0, beta=1):\n",
    "\t\tX = X.reshape(X.shape[0], -1)\n",
    "\t\treturn self.dense(X) * beta + alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5f8445-bc2a-4280-a975-c9edde925e79",
   "metadata": {},
   "source": [
    "This model has two optional inputs: `alpha`, which is an additive constant on the output from the dense layer, and `beta`, which is a multiplicative factor. Yes, it's redundant to have these factors after a dense layer which is doing a pretty similar thing, but this is meant just to demonstrate how to use the functions and to confirm that it's doing the expected thing.\n",
    "\n",
    "Let's start off by generating some random one-hot encodings and running the model on them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ba99f7-ed62-4585-a68a-c45fd7b4869a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3154, -0.1625, -0.3183],\n",
       "        [-0.0866,  0.5461, -0.0244],\n",
       "        [ 0.3089, -0.2828, -0.1485],\n",
       "        [ 0.1671, -0.1341, -0.3094],\n",
       "        [-0.0627,  0.0088,  0.3471]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tangermeme.utils import random_one_hot\n",
    "torch.manual_seed(0)\n",
    "\n",
    "X = random_one_hot((5, 4, 10), random_state=0).float()\n",
    "model = FlattenDense()\n",
    "\n",
    "y = model(X)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5954e38d-4655-4fc1-9757-f31643f8115e",
   "metadata": {},
   "source": [
    "#### Apply Pairwise\n",
    "\n",
    "`apply_pairwise` is the correct function to use if you have data that has two axes, where one of the axes is sequences, and the other axis contains multiple tensors of paired information. As an example, if you have a DragoNNFruit model which makes predictions for chromatin accessibility for each cell in a single-cell ATAC-seq experiment, the inputs are sequences, a vector representing the state of the cell, and the read depth of the cell. Because cell state and read depth are paired -- both come from the same cell -- you want to do the product between `X` and `(cell_state, read_depth)` such that you get $(X_0, c_0, r_0), (X_0, c_1, r_1), (X_0, c_2, r_2)...$. Importantly, you do not want to do the full cross product because that will create examples where the read depths and cell states come from different cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0035f43-8f65-4796-8e0c-3f52d65f8e09",
   "metadata": {},
   "source": [
    "##### Predict\n",
    "\n",
    "We can begin by checking what the predictions would be when using this function with arguments that only have a batch size of 1. Conceptually, this should be identical to just running the predict function, and we can compare our results here to the predictions that we got above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6517acfe-9362-4539-be75-53d9de279e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3154, -0.1625, -0.3183],\n",
       "        [-0.0866,  0.5461, -0.0244],\n",
       "        [ 0.3089, -0.2828, -0.1485],\n",
       "        [ 0.1671, -0.1341, -0.3094],\n",
       "        [-0.0627,  0.0088,  0.3471]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tangermeme.predict import predict\n",
    "from tangermeme.product import apply_pairwise\n",
    "\n",
    "torch.manual_seed(0)\n",
    "alpha = torch.zeros(1, 1)\n",
    "beta = torch.ones(1, 1)\n",
    "\n",
    "y_product = apply_pairwise(predict, model, X, args=(alpha, beta))[:, 0]\n",
    "y_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610f7b51-d38a-42a6-b47c-b2a597f87feb",
   "metadata": {},
   "source": [
    "Looks like the values are identical, although we do have to index a little bit because the additional index corresponds to the length of the argument tensors.\n",
    "\n",
    "Next, we can look at what happens when we set `alpha` and `beta` to be more than just one example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ac9d44-f6ee-4996-ad35-29a41d442428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3154, -0.1625, -0.3183],\n",
       "         [-0.3154, -0.1625, -0.3183]],\n",
       "\n",
       "        [[-0.0866,  0.5461, -0.0244],\n",
       "         [-0.0866,  0.5461, -0.0244]],\n",
       "\n",
       "        [[ 0.3089, -0.2828, -0.1485],\n",
       "         [ 0.3089, -0.2828, -0.1485]],\n",
       "\n",
       "        [[ 0.1671, -0.1341, -0.3094],\n",
       "         [ 0.1671, -0.1341, -0.3094]],\n",
       "\n",
       "        [[-0.0627,  0.0088,  0.3471],\n",
       "         [-0.0627,  0.0088,  0.3471]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = torch.zeros(2, 1)\n",
    "beta = torch.ones(2, 1)\n",
    "\n",
    "y_product = apply_pairwise(predict, model, X, args=(alpha, beta))\n",
    "y_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0254761c-0d7b-4afe-9719-18464de62df5",
   "metadata": {},
   "source": [
    "Here, we see that the results are the same for adjacent predictions, which makes sense because `alpha` is just zeros in both cases and `beta` is just ones in both cases. Next, we can see that changing the values of `alpha` and `beta` will lead to different predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b746e19-d111-4203-a5c2-abfbb50fa3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.2283,  1.8950,  2.2344],\n",
       "         [-0.4727, -0.3858, -0.4743]],\n",
       "\n",
       "        [[ 1.7297,  0.3512,  1.5941],\n",
       "         [-0.3427,  0.0170, -0.3073]],\n",
       "\n",
       "        [[ 0.8680,  2.1571,  1.8646],\n",
       "         [-0.1178, -0.4542, -0.3779]],\n",
       "\n",
       "        [[ 1.1769,  1.8331,  2.2151],\n",
       "         [-0.1984, -0.3696, -0.4693]],\n",
       "\n",
       "        [[ 1.6775,  1.5218,  0.7847],\n",
       "         [-0.3290, -0.2884, -0.0961]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = torch.randn(2, 1)\n",
    "beta = torch.randn(2, 1)\n",
    "\n",
    "y_product = apply_pairwise(predict, model, X, args=(alpha, beta))\n",
    "y_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8e2ba0-5bf7-446b-a7ca-d5cb0a4fa975",
   "metadata": {},
   "source": [
    "As mentioned repeatedly, `tangermeme` tries to be as assumption-free as possible. This means that `alpha` and `beta` can be any shape that works with the math provided in the implementation. Because three outputs are generated for each example, we can have our `alpha` and `beta` tensors also have three dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16a25e23-898d-4989-b972-b9c3000bb5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = torch.zeros(1, 3)\n",
    "beta = torch.ones(1, 3)\n",
    "\n",
    "y_product = apply_pairwise(predict, model, X, args=(alpha, beta))\n",
    "y_product.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04021c14-6e64-4b64-97a0-bb98fc2d30ee",
   "metadata": {},
   "source": [
    "##### Attributions\n",
    "\n",
    "In addition to working with the `predict` function, these product functions can take in any other tangermeme function and apply them to the respect product of examples. This means that we can apply `deep_lift_shap` just eas easily as we apply `predict`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e24a7742-1592-4ca8-b636-87501b4a1565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 4, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tangermeme.deep_lift_shap import deep_lift_shap\n",
    "\n",
    "y_attr = apply_pairwise(deep_lift_shap, model, X, args=(alpha, beta))\n",
    "y_attr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bd0258-9937-4152-a3b7-207a534e064d",
   "metadata": {},
   "source": [
    "The shape follows from the previous examples: the first dimension is the size of `X`, the second dimension is the size of `alpha` and `beta`, and the remaining dimensions are those from the function being applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeca905-3a96-4763-99b2-dda39f10cdad",
   "metadata": {},
   "source": [
    "##### Marginalize\n",
    "\n",
    "Next, we can apply `marginalize` just as easily as we can apply `predict`. A major difference in the output here will be that there will be two tensors returned: one before making the substitution, and one after. Importantly, when using `apply_pairwise` and `apply_product` additional arguments can be passed into the inner function positionally as simply more arguments. Note the \"TGA\" below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e86c651-38b9-497d-8d10-e7069e3d65bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.3154, -0.1625, -0.3183],\n",
       "         [-0.0866,  0.5461, -0.0244],\n",
       "         [ 0.3089, -0.2828, -0.1485],\n",
       "         [ 0.1671, -0.1341, -0.3094],\n",
       "         [-0.0627,  0.0088,  0.3471]]),\n",
       " tensor([[-0.0615, -0.2536, -0.1744],\n",
       "         [-0.1973,  0.6584,  0.2584],\n",
       "         [ 0.2046,  0.1125, -0.0750],\n",
       "         [ 0.0317,  0.0328, -0.1166],\n",
       "         [ 0.0374,  0.1503,  0.4602]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tangermeme.marginalize import marginalize\n",
    "\n",
    "y_before, y_after = apply_pairwise(marginalize, model, X, motif=\"TGA\", args=(alpha, beta))\n",
    "y_before[:, 0], y_after[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1810265-9c32-4718-afed-a9f7d2902144",
   "metadata": {},
   "source": [
    "If we wanted to also pass in an argument for `start` we could just keep adding in arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d91ffb0-f0ed-47d9-a9b1-632e8e572f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.3154, -0.1625, -0.3183],\n",
       "         [-0.0866,  0.5461, -0.0244],\n",
       "         [ 0.3089, -0.2828, -0.1485],\n",
       "         [ 0.1671, -0.1341, -0.3094],\n",
       "         [-0.0627,  0.0088,  0.3471]]),\n",
       " tensor([[-0.3603, -0.2071, -0.2159],\n",
       "         [-0.1005,  0.3231, -0.1471],\n",
       "         [ 0.1569, -0.3900, -0.1329],\n",
       "         [ 0.1721, -0.2478, -0.2496],\n",
       "         [-0.1870, -0.0630,  0.1463]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_before, y_after = apply_pairwise(marginalize, model, X, motif=\"TGA\", start=0, args=(alpha, beta))\n",
    "y_before[:, 0], y_after[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4928b5-2239-4994-97c8-4dde216d4be6",
   "metadata": {},
   "source": [
    "Note that the values before making the substitution are the same, but the values after are different.\n",
    "\n",
    "Naturally, being able to pass in any function, e.g., marginalize, and being able to pass in any arguments to those functions makes it possible to nest functions even further! After all, `marginalize` itself defaults to predictions but can apply other functions just as easily. Although the signature will be a little bit messy, we can easily use `apply_pairwise` with the `marginalize` function that itself is applying `deep_lift_shap` instead of `predict`! All we have to do is use the `additional_func_kwargs` argument, which is a dictionary of arguments that get passed directly into the provided func. This is somewhat redundant with passing in arguments directly, but circumvents issues where you want to pass an argument into `func` that is the same name as an argument needed by `apply_pairwise`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d24dd7e-8490-480e-9760-1db8067d855a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 1, 4, 10]), torch.Size([5, 1, 4, 10]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_before, y_after = apply_pairwise(marginalize, model, X, motif=\"TGA\", alphabet=['A', 'C', 'G', 'T',], \n",
    "                                   additional_func_kwargs={'func': deep_lift_shap}, args=(alpha, beta))\n",
    "y_before.shape, y_after.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c65991-2e0c-42aa-b504-d5a8be4588a9",
   "metadata": {},
   "source": [
    "Even though it is a little messy to define the signature, look at how easy it is to do marginalized attributions across a product of examples, and you have the power to change any of the arguments in any of the functions called along the way. You can now do it in a single line instead of having to think of how to efficiently do each of the parts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5311f5-13c9-4bd1-a640-ef937002d426",
   "metadata": {},
   "source": [
    "#### Apply Product\n",
    "\n",
    "In contrast to `apply_pairwise`, `apply_product` is a more general function that will construct examples from the product of any number of arguments that have been passed in. If you have a model that takes in many inputs and each input corresponds to an orthogonal sort of value, e.g., a model that takes in DNA sequence, and protein sequence, and some sort of conditions, etc, and predicts something like binding structure, this would be the function for you. The signature is identical to `apply_pairwise` except the function is applied to more constructed examples.\n",
    "\n",
    "Let's start off by seeing this in action with the same prediction as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac74e8a9-6972-4720-82f0-ab733a986d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3154, -0.1625, -0.3183],\n",
       "        [-0.0866,  0.5461, -0.0244],\n",
       "        [ 0.3089, -0.2828, -0.1485],\n",
       "        [ 0.1671, -0.1341, -0.3094],\n",
       "        [-0.0627,  0.0088,  0.3471]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tangermeme.product import apply_product\n",
    "\n",
    "alpha = torch.zeros(1, 1)\n",
    "beta = torch.ones(1, 1)\n",
    "\n",
    "y_product = apply_product(predict, model, X, args=(alpha, beta))[:, 0, 0]\n",
    "y_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdf7865-0ae9-45d6-8ac9-e0cfb7c0487b",
   "metadata": {},
   "source": [
    "Looks like we are getting the same thing as before, except that there is an additional axis that needs to be indexed into because on of the axes corresponds to `alpha` and one of them corresponds to `beta`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54c1f60-581e-4b45-a00b-1c6748219439",
   "metadata": {},
   "source": [
    "Since all we are doing is adding a value in a broadcasted manner, we can easily check by adding in the appropriate dimensions and doing the addition outside the context of this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7594536-2894-4d76-a1e9-d8dc3453afca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4000, -1.2470, -1.4028],\n",
       "         [-1.7140, -1.5611, -1.7168],\n",
       "         [ 0.0879,  0.2409,  0.0851]],\n",
       "\n",
       "        [[-1.1711, -0.5384, -1.1089],\n",
       "         [-1.4852, -0.8525, -1.4230],\n",
       "         [ 0.3167,  0.9494,  0.3790]],\n",
       "\n",
       "        [[-0.7756, -1.3673, -1.2330],\n",
       "         [-1.0897, -1.6814, -1.5471],\n",
       "         [ 0.7123,  0.1206,  0.2548]],\n",
       "\n",
       "        [[-0.9174, -1.2186, -1.3939],\n",
       "         [-1.2315, -1.5327, -1.7080],\n",
       "         [ 0.5704,  0.2693,  0.0940]],\n",
       "\n",
       "        [[-1.1472, -1.0757, -0.7374],\n",
       "         [-1.4613, -1.3898, -1.0515],\n",
       "         [ 0.3407,  0.4122,  0.7505]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = torch.randn(3, 1)\n",
    "\n",
    "y_product = apply_product(predict, model, X, args=(alpha,))\n",
    "y_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62f80cc6-524d-4b8f-8108-244889f56432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4000, -1.2470, -1.4028],\n",
       "         [-1.7140, -1.5611, -1.7168],\n",
       "         [ 0.0879,  0.2409,  0.0851]],\n",
       "\n",
       "        [[-1.1711, -0.5384, -1.1089],\n",
       "         [-1.4852, -0.8525, -1.4230],\n",
       "         [ 0.3167,  0.9494,  0.3790]],\n",
       "\n",
       "        [[-0.7756, -1.3673, -1.2330],\n",
       "         [-1.0897, -1.6814, -1.5471],\n",
       "         [ 0.7123,  0.1206,  0.2548]],\n",
       "\n",
       "        [[-0.9174, -1.2186, -1.3939],\n",
       "         [-1.2315, -1.5327, -1.7080],\n",
       "         [ 0.5704,  0.2693,  0.0940]],\n",
       "\n",
       "        [[-1.1472, -1.0757, -0.7374],\n",
       "         [-1.4613, -1.3898, -1.0515],\n",
       "         [ 0.3407,  0.4122,  0.7505]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unsqueeze(1) + alpha.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5b87e1-6e62-4402-b7b0-0eaa9a346ada",
   "metadata": {},
   "source": [
    "Same values. If we add in a `beta` value, we see the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95994671-bc0a-46a3-9a4a-6f317025d147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3617,  1.4486,  1.3601],\n",
       "         [-0.4727, -0.3858, -0.4743],\n",
       "         [-2.3581, -2.2711, -2.3597]],\n",
       "\n",
       "        [[ 1.4918,  1.8514,  1.5271],\n",
       "         [-0.3427,  0.0170, -0.3073],\n",
       "         [-2.2280, -1.8684, -2.1926]],\n",
       "\n",
       "        [[ 1.7166,  1.3803,  1.4566],\n",
       "         [-0.1178, -0.4542, -0.3779],\n",
       "         [-2.0032, -2.3395, -2.2632]],\n",
       "\n",
       "        [[ 1.6360,  1.4648,  1.3651],\n",
       "         [-0.1984, -0.3696, -0.4693],\n",
       "         [-2.0838, -2.2550, -2.3546]],\n",
       "\n",
       "        [[ 1.5054,  1.5460,  1.7383],\n",
       "         [-0.3290, -0.2884, -0.0961],\n",
       "         [-2.2144, -2.1738, -1.9815]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "alpha = torch.randn(3, 1)\n",
    "beta = torch.randn(1, 1)\n",
    "\n",
    "y_product = apply_product(predict, model, X, args=(alpha, beta))[:, :, 0]\n",
    "y_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34be1d26-bfb8-4146-a8ad-1fdac5a78521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3617,  1.4486,  1.3601],\n",
       "         [-0.4727, -0.3858, -0.4743],\n",
       "         [-2.3581, -2.2711, -2.3597]],\n",
       "\n",
       "        [[ 1.4918,  1.8514,  1.5271],\n",
       "         [-0.3427,  0.0170, -0.3073],\n",
       "         [-2.2280, -1.8684, -2.1926]],\n",
       "\n",
       "        [[ 1.7166,  1.3803,  1.4566],\n",
       "         [-0.1178, -0.4542, -0.3779],\n",
       "         [-2.0032, -2.3395, -2.2632]],\n",
       "\n",
       "        [[ 1.6360,  1.4648,  1.3651],\n",
       "         [-0.1984, -0.3696, -0.4693],\n",
       "         [-2.0838, -2.2550, -2.3546]],\n",
       "\n",
       "        [[ 1.5054,  1.5460,  1.7383],\n",
       "         [-0.3290, -0.2884, -0.0961],\n",
       "         [-2.2144, -2.1738, -1.9815]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unsqueeze(1) * beta.unsqueeze(0) + alpha.unsqueeze(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
